package pl.marcinmilkowski.word_sketch.query;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.queries.spans.SpanQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.store.FSDirectory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import pl.marcinmilkowski.word_sketch.grammar.CQLParser;
import pl.marcinmilkowski.word_sketch.grammar.CQLPattern;

import java.io.IOException;
import java.nio.file.Paths;
import java.util.*;

/**
 * Query executor that finds collocations and computes association scores.
 */
public class WordSketchQueryExecutor {

    private static final Logger logger = LoggerFactory.getLogger(WordSketchQueryExecutor.class);

    private final IndexSearcher searcher;
    private final CQLToLuceneCompiler compiler;
    private final String indexPath;
    private final IndexReader reader;

    public WordSketchQueryExecutor(String indexPath) throws IOException {
        this.indexPath = indexPath;
        this.reader = DirectoryReader.open(FSDirectory.open(Paths.get(indexPath)));
        this.searcher = new IndexSearcher(reader);
        this.compiler = new CQLToLuceneCompiler();
    }

    /**
     * Find collocations for a headword using a CQL pattern.
     * The pattern should define what types of words appear near the headword.
     *
     * If headword is empty or null, performs a simple frequency query using the pattern.
     */
    public List<WordSketchResult> findCollocations(String headword, String cqlPattern,
                                                    double minLogDice, int maxResults)
            throws IOException {

        // Parse the collocate pattern
        CQLPattern collocatePattern = new CQLParser().parse(cqlPattern);

        // Debug: Check pattern parsing
        System.out.println(String.format("  DEBUG: Pattern '%s' has %d elements",
            cqlPattern, collocatePattern.getElements().size()));
        if (!collocatePattern.getElements().isEmpty()) {
            var elem = collocatePattern.getElements().get(0);
            System.out.println(String.format("  DEBUG: element: target='%s', minDist=%d, maxDist=%d",
                elem.getTarget(), elem.getMinDistance(), elem.getMaxDistance()));
        }

        // Build pattern query
        SpanQuery patternQuery = compiler.compile(collocatePattern);

        Map<String, List<String>> examples = new HashMap<>();
        Map<String, Long> lemmaFreqs = new HashMap<>();
        Map<String, String> lemmaPos = new HashMap<>();

        // Get headword frequency
        long headwordFreq = (headword == null || headword.isEmpty()) ? 1 : getTotalFrequency(headword);
        if (headword != null && !headword.isEmpty() && headwordFreq == 0) {
            System.out.println(String.format("  Headword '%s' not found in corpus", headword));
            return Collections.emptyList();
        }

        // Build set of sentences containing the headword, with headword position
        Map<String, Integer> headwordSentences = new HashMap<>();
        if (headword != null && !headword.isEmpty()) {
            TermQuery headwordQuery = new TermQuery(new Term("lemma", headword.toLowerCase()));
            TopDocs headwordHits = searcher.search(headwordQuery, 100000);
            for (ScoreDoc hd : headwordHits.scoreDocs) {
                Document doc = searcher.storedFields().document(hd.doc);
                String sentence = doc.get("sentence");
                if (sentence != null) {
                    sentence = sentence.trim(); // Normalize whitespace
                    int pos = Integer.parseInt(doc.get("position"));
                    // Store the minimum position for each sentence
                    headwordSentences.merge(sentence, pos, Math::min);
                }
            }
            System.out.println(String.format("  Headword '%s' occurs in %,d sentences", headword, headwordSentences.size()));
        }

        // Get max distance from pattern
        int maxDist = 3;
        if (!collocatePattern.getElements().isEmpty()) {
            maxDist = collocatePattern.getElements().get(0).getMaxDistance();
            if (maxDist < 0) maxDist = 3;
        }

        // Search for pattern matches
        TopDocs topDocs = searcher.search(patternQuery, 10000);
        ScoreDoc[] hits = topDocs.scoreDocs;

        System.out.println(String.format("  Found %,d pattern matches", hits.length));

        int skippedHeadword = 0;
        int processed = 0;
        int sentenceMatches = 0;

        for (ScoreDoc hit : hits) {
            Document doc = searcher.storedFields().document(hit.doc);
            String collocateLemma = doc.get("lemma");
            String pos = doc.get("tag");
            String sentence = doc.get("sentence");
            int collocatePos = Integer.parseInt(doc.get("position"));

            if (processed < 3) {
                System.out.println("      DEBUG: collocateLemma=" + collocateLemma + ", sentence=" + (sentence != null ? sentence.substring(0, Math.min(30, sentence.length())) : "null"));
            }

            if (collocateLemma == null) continue;

            // Skip the headword itself
            if (headword != null && !headword.isEmpty() && collocateLemma.equalsIgnoreCase(headword)) {
                skippedHeadword++;
                continue;
            }

            // Check if this pattern match is in a sentence with the headword
            boolean nearHeadword = headwordSentences.isEmpty(); // No headword = accept all
            if (!headwordSentences.isEmpty() && sentence != null) {
                Integer headwordPos = headwordSentences.get(sentence);
                // Debug: check if sentence exists in headwordSentences
                if (processed < 3 && sentence != null) {
                    System.out.println("      DEBUG: sentence='" + sentence.substring(0, Math.min(50, sentence.length())) + "'");
                    System.out.println("      DEBUG: sentence in headwordSentences? " + headwordSentences.containsKey(sentence));
                }
                if (headwordPos != null) {
                    // Check position distance
                    int posDistance = Math.abs(collocatePos - headwordPos);
                    if (posDistance <= maxDist) {
                        nearHeadword = true;
                        sentenceMatches++;
                    }
                }
            }

            if (!nearHeadword) continue;

            // Count frequency
            lemmaFreqs.merge(collocateLemma.toLowerCase(), 1L, Long::sum);
            lemmaPos.putIfAbsent(collocateLemma.toLowerCase(), pos != null ? pos.toLowerCase() : "");

            String key = collocateLemma.toLowerCase();
            if (!examples.containsKey(key)) {
                examples.put(key, new ArrayList<>());
            }
            if (examples.get(key).size() < 5) {
                examples.get(key).add(sentence);
            }

            processed++;
            if (processed >= 5000) break;
        }

        System.out.println(String.format("  Processed: %d, skipped headword: %d, unique collocates: %d, sentenceMatches: %d",
            processed, skippedHeadword, lemmaFreqs.size(), sentenceMatches));

        // Calculate logDice for each collocate
        List<WordSketchResult> results = new ArrayList<>();
        for (Map.Entry<String, Long> entry : lemmaFreqs.entrySet()) {
            String lemma = entry.getKey();
            long freq = entry.getValue();

            long collocateTotalFreq = getTotalFrequency(lemma);
            if (collocateTotalFreq == 0) collocateTotalFreq = 1;

            double logDice = calculateLogDice(freq, headwordFreq, collocateTotalFreq);

            if (logDice >= minLogDice || minLogDice == 0) {
                double relFreq = (double) freq / Math.max(1, hits.length);
                WordSketchResult result = new WordSketchResult(
                    lemma,
                    lemmaPos.getOrDefault(lemma, ""),
                    freq,
                    logDice,
                    relFreq,
                    examples.getOrDefault(lemma, Collections.emptyList())
                );
                results.add(result);
            }
        }

        results.sort((a, b) -> Double.compare(b.getLogDice(), a.getLogDice()));

        return results.subList(0, Math.min(maxResults, results.size()));
    }

    private long getTotalFrequency(String lemma) throws IOException {
        return reader.docFreq(new Term("lemma", lemma));
    }

    /**
     * Calculate logDice association score.
     * logDice = log2(2 * f(AB) / (f(A) + f(B))) + 14
     * Score ranges from 0 to 14, where 14 = perfect association.
     */
    private double calculateLogDice(long freqAB, long freqA, long freqB) {
        if (freqA == 0 || freqB == 0) {
            return 0.0;
        }
        double numerator = 2.0 * freqAB;
        double denominator = freqA + freqB;
        if (denominator == 0) {
            return 0.0;
        }
        double logDice = Math.log(numerator / denominator) / Math.log(2) + 14;
        return Math.max(0, Math.min(14, logDice)); // Clamp to [0, 14]
    }

    /**
     * Execute a custom CQL query and return matching sentences.
     */
    public List<ConcordanceResult> executeQuery(String cqlPattern, int maxResults)
            throws IOException {

        CQLPattern pattern = new CQLParser().parse(cqlPattern);
        SpanQuery query = compiler.compile(pattern);

        TopDocs topDocs = searcher.search(query, maxResults);
        ScoreDoc[] hits = topDocs.scoreDocs;

        List<ConcordanceResult> results = new ArrayList<>();

        for (ScoreDoc hit : hits) {
            Document doc = searcher.storedFields().document(hit.doc);
            results.add(new ConcordanceResult(
                doc.get("sentence"),
                doc.get("lemma"),
                doc.get("tag"),
                doc.get("word"),
                Integer.parseInt(doc.get("start_offset")),
                Integer.parseInt(doc.get("end_offset"))
            ));
        }

        return results;
    }

    public static class WordSketchResult {
        private final String lemma;
        private final String pos;
        private final long frequency;
        private final double logDice;
        private final double relativeFrequency;
        private final List<String> examples;

        public WordSketchResult(String lemma, String pos, long frequency,
                               double logDice, double relativeFrequency,
                               List<String> examples) {
            this.lemma = lemma;
            this.pos = pos;
            this.frequency = frequency;
            this.logDice = logDice;
            this.relativeFrequency = relativeFrequency;
            this.examples = examples;
        }

        public String getLemma() { return lemma; }
        public String getPos() { return pos; }
        public long getFrequency() { return frequency; }
        public double getLogDice() { return logDice; }
        public double getRelativeFrequency() { return relativeFrequency; }
        public List<String> getExamples() { return examples; }
    }

    public static class ConcordanceResult {
        private final String sentence;
        private final String lemma;
        private final String tag;
        private final String word;
        private final int startOffset;
        private final int endOffset;

        public ConcordanceResult(String sentence, String lemma, String tag,
                                String word, int startOffset, int endOffset) {
            this.sentence = sentence;
            this.lemma = lemma;
            this.tag = tag;
            this.word = word;
            this.startOffset = startOffset;
            this.endOffset = endOffset;
        }

        public String getSentence() { return sentence; }
        public String getLemma() { return lemma; }
        public String getTag() { return tag; }
        public String getWord() { return word; }
        public int getStartOffset() { return startOffset; }
        public int getEndOffset() { return endOffset; }
    }

    public void close() throws IOException {
        reader.close();
    }

    /**
     * Get frequency of a specific lemma in the index.
     */
    public long getLemmaFrequency(String lemma) throws IOException {
        return reader.docFreq(new Term("lemma", lemma));
    }

    /**
     * Find words by POS tag pattern (e.g., "JJ*" for adjectives, "NN*" for nouns).
     */
    public List<WordSketchResult> findByTagPattern(String tagPattern, int maxResults) throws IOException {
        org.apache.lucene.index.Term term = new org.apache.lucene.index.Term("tag", tagPattern.replace("*", ".*"));
        org.apache.lucene.search.WildcardQuery query = new org.apache.lucene.search.WildcardQuery(term);
        org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper<?> spanQuery =
            new org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper<>(query);

        TopDocs topDocs = searcher.search(spanQuery, maxResults * 10);
        ScoreDoc[] hits = topDocs.scoreDocs;

        Map<String, Long> lemmaFreqs = new HashMap<>();
        Map<String, String> examples = new HashMap<>();

        for (ScoreDoc hit : hits) {
            Document doc = searcher.storedFields().document(hit.doc);
            String lemma = doc.get("lemma");
            String sentence = doc.get("sentence");

            if (lemma != null) {
                lemmaFreqs.merge(lemma, 1L, Long::sum);
                if (!examples.containsKey(lemma)) {
                    examples.put(lemma, sentence);
                }
            }
        }

        List<WordSketchResult> results = new ArrayList<>();
        for (Map.Entry<String, Long> entry : lemmaFreqs.entrySet()) {
            results.add(new WordSketchResult(
                entry.getKey(), "", entry.getValue(),
                Math.log10(entry.getValue() + 1) * 2,
                (double) entry.getValue() / hits.length,
                Collections.singletonList(examples.get(entry.getKey()))
            ));
        }

        results.sort((a, b) -> Long.compare(b.getFrequency(), a.getFrequency()));
        return results.subList(0, Math.min(maxResults, results.size()));
    }

    public static void main(String[] args) throws IOException {
        String indexPath = args.length > 0 ? args[0] : "target/corpus-1m";

        System.out.println("Word Sketch Query Executor - 1M Token Corpus");
        System.out.println("==============================================");
        System.out.println(String.format("Index: %s", indexPath));

        try (WordSketchExecutor executor = new WordSketchExecutor(indexPath)) {
            // Debug: Check what tags exist in the index
            System.out.println("Checking index structure...");
            System.out.println("Sample lemma frequencies:");
            String[] testLemmas = {"time", "problem", "good", "people", "new"};
            for (String lemma : testLemmas) {
                long freq = executor.executor.getLemmaFrequency(lemma);
                System.out.println("  " + lemma + ": " + freq);
            }

            // Debug: Check what the CQL pattern parses to
            String testPattern = "[tag=\"JJ.*\"]";
            System.out.println("\nTesting CQL pattern: " + testPattern);
            try {
                var parsed = new CQLParser().parse(testPattern);
                System.out.println("Parsed elements: " + parsed.getElements().size());
                for (var elem : parsed.getElements()) {
                    System.out.println("  target='" + elem.getTarget() + "', position=" + elem.getPosition() +
                        ", hasConstraint=" + (elem.getConstraint() != null));
                    if (elem.getConstraint() != null) {
                        System.out.println("    constraint: field=" + elem.getConstraint().getField() +
                            ", pattern=" + elem.getConstraint().getPattern());
                    }
                }

                // Compile to see what query is produced
                var compiler = new CQLToLuceneCompiler();
                var query = compiler.compile(parsed);
                System.out.println("Query type: " + query.getClass().getSimpleName());
            } catch (Exception e) {
                System.out.println("Parse error: " + e.getMessage());
            }

            // Test a direct query
            System.out.println("\nTesting direct tag query [tag=\"JJ\"]...");
            try {
                var directResults = executor.executor.executeQuery("[tag=\"JJ\"]", 10);
                System.out.println("Direct query found " + directResults.size() + " results");
                for (var r : directResults) {
                    System.out.println("  " + r.getWord() + "/" + r.getTag() + ": " +
                        (r.getSentence() != null ? r.getSentence().substring(0, Math.min(80, r.getSentence().length())) : "null"));
                }
            } catch (Exception e) {
                System.out.println("Direct query error: " + e.getMessage());
            }

            // Debug: Check the actual Lucene query being built
            System.out.println("\nDebug: Testing wildcard query directly...");
            try {
                var pattern = new CQLParser().parse("[tag=\"JJ*\"]");
                System.out.println("Pattern elements: " + pattern.getElements().size());
                var compiler = new CQLToLuceneCompiler();
                var query = compiler.compile(pattern);
                System.out.println("Query: " + query);

                // Test search
                var searcher = new IndexSearcher(executor.executor.reader);
                var topDocs = searcher.search(query, 100);
                System.out.println("Search found " + topDocs.totalHits + " hits");
            } catch (Exception e) {
                System.out.println("Debug error: " + e.getMessage());
                e.printStackTrace();
            }
            System.out.println("\n=== Word Sketch: problem (adjectives) ===");
            System.out.println("Pattern: [tag=\"jj.*\"] ~ {0,3}");
            System.out.println();

            List<WordSketchResult> results = executor.findCollocations(
                "problem", "[tag=\"jj.*\"] ~ {0,3}", 0, 20);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }
            System.out.println();

            // Test adjective collocates of "time"
            System.out.println("=== Word Sketch: time (adjectives) ===");
            System.out.println("Pattern: [tag=\"jj.*\"] ~ {0,3}");
            System.out.println();

            results = executor.findCollocations("time", "[tag=\"jj.*\"] ~ {0,3}", 0, 20);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }
            System.out.println();

            // Test verbs with "people"
            System.out.println("=== Word Sketch: people (verbs) ===");
            System.out.println("Pattern: [tag=\"vb.*\"] ~ {0,3}");
            System.out.println();

            results = executor.findCollocations("people", "[tag=\"vb.*\"] ~ {0,3}", 0, 15);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }

        } catch (Exception e) {
            System.err.println("Error: " + e.getMessage());
            e.printStackTrace();
        }
    }

    /**
     * Simple wrapper for testing - uses WordSketchQueryExecutor internally.
     */
    public static class WordSketchExecutor implements AutoCloseable {
        private final WordSketchQueryExecutor executor;

        public WordSketchExecutor(String indexPath) throws IOException {
            this.executor = new WordSketchQueryExecutor(indexPath);
        }

        public List<WordSketchResult> findCollocations(String headword, String pattern,
                                                        double minLogDice, int maxResults) throws IOException {
            return executor.findCollocations(headword, pattern, minLogDice, maxResults);
        }

        @Override
        public void close() throws IOException {
            executor.close();
        }
    }
}
