package pl.marcinmilkowski.word_sketch.query;

import org.apache.lucene.document.Document;
import org.apache.lucene.index.DirectoryReader;
import org.apache.lucene.index.IndexReader;
import org.apache.lucene.index.Term;
import org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper;
import org.apache.lucene.queries.spans.SpanNearQuery;
import org.apache.lucene.queries.spans.SpanQuery;
import org.apache.lucene.search.IndexSearcher;
import org.apache.lucene.search.ScoreDoc;
import org.apache.lucene.search.TermQuery;
import org.apache.lucene.search.TopDocs;
import org.apache.lucene.search.WildcardQuery;
import org.apache.lucene.store.FSDirectory;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import pl.marcinmilkowski.word_sketch.grammar.CQLParser;
import pl.marcinmilkowski.word_sketch.grammar.CQLPattern;

import java.io.IOException;
import java.nio.file.Paths;
import java.util.*;

/**
 * Query executor that finds collocations and computes association scores.
 */
public class WordSketchQueryExecutor {

    private static final Logger logger = LoggerFactory.getLogger(WordSketchQueryExecutor.class);

    private final IndexSearcher searcher;
    private final CQLToLuceneCompiler compiler;
    private final String indexPath;
    private final IndexReader reader;

    public WordSketchQueryExecutor(String indexPath) throws IOException {
        this.indexPath = indexPath;
        this.reader = DirectoryReader.open(FSDirectory.open(Paths.get(indexPath)));
        this.searcher = new IndexSearcher(reader);
        this.compiler = new CQLToLuceneCompiler();
    }

    /**
     * Find collocations for a headword using a CQL pattern.
     * Uses SpanNearQuery for efficient pattern matching - O(1) query instead of O(n) scans.
     */
    public List<WordSketchResult> findCollocations(String headword, String cqlPattern,
                                                    double minLogDice, int maxResults)
            throws IOException {

        // Get headword frequency
        long headwordFreq = (headword == null || headword.isEmpty()) ? 1 : getTotalFrequency(headword);
        if (headword != null && !headword.isEmpty() && headwordFreq == 0) {
            System.out.println(String.format("  Headword '%s' not found in corpus", headword));
            return Collections.emptyList();
        }

        // Parse the collocate pattern to get constraints
        CQLPattern collocatePattern = new CQLParser().parse(cqlPattern);

        System.out.println(String.format("  DEBUG: Pattern '%s' has %d elements",
            cqlPattern, collocatePattern.getElements().size()));

        // Get the constraint pattern (e.g., "jj.*" from [tag="jj.*"])
        String constraintField = null;
        String constraintPattern = null;
        if (!collocatePattern.getElements().isEmpty()) {
            var elem = collocatePattern.getElements().get(0);
            if (elem.getConstraint() != null) {
                constraintField = elem.getConstraint().getField();
                constraintPattern = elem.getConstraint().getPattern();
            } else if (elem.getTarget() != null && !elem.getTarget().isEmpty()) {
                String target = elem.getTarget();
                // If target looks like a tag pattern (contains wildcard), treat as tag constraint
                if (target.contains(".*") || target.contains("?") || target.matches("^[a-zA-Z]+$")) {
                    constraintField = "tag";
                    constraintPattern = target;
                } else {
                    // Treat as word constraint
                    constraintField = "word";
                    constraintPattern = target;
                }
            }
            System.out.println(String.format("  DEBUG: target='%s', minDist=%d, maxDist=%d, constraintField='%s', constraintPattern='%s'",
                elem.getTarget(), elem.getMinDistance(), elem.getMaxDistance(), constraintField, constraintPattern));
        }

        if (headword == null || headword.isEmpty()) {
            System.out.println("  No headword specified");
            return Collections.emptyList();
        }

        // Build a SpanNearQuery: headword near (tagPattern | targetWord)
        // Pattern: (headword) [tagPattern | targetWord]
        int maxDist = 3;
        if (!collocatePattern.getElements().isEmpty()) {
            maxDist = collocatePattern.getElements().get(0).getMaxDistance();
            if (maxDist < 0) maxDist = 3;
        }

        System.out.println(String.format("  Headword '%s' occurs in %,d positions", headword, headwordFreq));

        // Create a SpanNearQuery for: headword NEAR collocate
        SpanQuery headwordSpan = new org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper<>(
            new TermQuery(new Term("lemma", headword.toLowerCase())));

        SpanQuery collocateSpan;
        if (tagPattern != null) {
            // Use tag pattern for collocate
            WildcardQuery tagQuery = new WildcardQuery(new Term("tag", tagPattern.toLowerCase()));
            collocateSpan = new SpanMultiTermQueryWrapper<>(tagQuery);
        } else if (targetWord != null) {
            // Use specific word as collocate
            collocateSpan = new SpanMultiTermQueryWrapper<>(
                new TermQuery(new Term("lemma", targetWord.toLowerCase())));
        } else {
            // No specific pattern - match any word
            WildcardQuery anyQuery = new WildcardQuery(new Term("lemma", "*"));
            collocateSpan = new SpanMultiTermQueryWrapper<>(anyQuery);
        }

        // Combine: headword NEAR collocate (inOrder=false to find both sides)
        SpanQuery[] clauses = new SpanQuery[] { headwordSpan, collocateSpan };
        SpanNearQuery nearQuery = new SpanNearQuery(clauses, maxDist, false, true);

        System.out.println(String.format("  Executing SpanNearQuery for %s near %s...", headword, tagPattern != null ? tagPattern : targetWord));

        TopDocs topDocs = searcher.search(nearQuery, 10000);

        System.out.println(String.format("  Found %,d matches", topDocs.scoreDocs.length));

        // Aggregate results from matches
        Map<String, Long> lemmaFreqs = new HashMap<>();
        Map<String, String> lemmaPos = new HashMap<>();
        Map<String, List<String>> examples = new HashMap<>();

        int matchCount = 0;
        for (ScoreDoc hit : topDocs.scoreDocs) {
            Document doc = searcher.storedFields().document(hit.doc);
            String lemma = doc.get("lemma");
            String tag = doc.get("tag");
            String sentence = doc.get("sentence");

            if (lemma == null) continue;
            if (lemma.equalsIgnoreCase(headword)) continue;

            // Check tag pattern if specified
            if (tagPattern != null && tag != null) {
                if (!tag.toLowerCase().matches(tagPattern.toLowerCase())) {
                    continue;
                }
            }

            matchCount++;
            String key = lemma.toLowerCase();

            lemmaFreqs.merge(key, 1L, Long::sum);
            lemmaPos.putIfAbsent(key, tag != null ? tag.toLowerCase() : "");

            if (!examples.containsKey(key)) {
                examples.put(key, new ArrayList<>());
            }
            if (examples.get(key).size() < 5 && sentence != null) {
                examples.get(key).add(sentence.trim());
            }
        }

        System.out.println(String.format("  Processed: %d matches, unique collocates: %d", matchCount, lemmaFreqs.size()));

        // Calculate logDice for each collocate
        int totalMatches = Math.max(1, matchCount);
        List<WordSketchResult> results = new ArrayList<>();
        for (Map.Entry<String, Long> entry : lemmaFreqs.entrySet()) {
            String lemma = entry.getKey();
            long freq = entry.getValue();

            long collocateTotalFreq = getTotalFrequency(lemma);
            if (collocateTotalFreq == 0) collocateTotalFreq = 1;

            double logDice = calculateLogDice(freq, headwordFreq, collocateTotalFreq);

            if (logDice >= minLogDice || minLogDice == 0) {
                double relFreq = (double) freq / totalMatches;
                WordSketchResult result = new WordSketchResult(
                    lemma,
                    lemmaPos.getOrDefault(lemma, ""),
                    freq,
                    logDice,
                    relFreq,
                    examples.getOrDefault(lemma, Collections.emptyList())
                );
                results.add(result);
            }
        }

        results.sort((a, b) -> Double.compare(b.getLogDice(), a.getLogDice()));

        return results.subList(0, Math.min(maxResults, results.size()));
    }

    private long getTotalFrequency(String lemma) throws IOException {
        return reader.docFreq(new Term("lemma", lemma));
    }

    /**
     * Calculate logDice association score.
     * logDice = log2(2 * f(AB) / (f(A) + f(B))) + 14
     * Score ranges from 0 to 14, where 14 = perfect association.
     */
    private double calculateLogDice(long freqAB, long freqA, long freqB) {
        if (freqA == 0 || freqB == 0) {
            return 0.0;
        }
        double numerator = 2.0 * freqAB;
        double denominator = freqA + freqB;
        if (denominator == 0) {
            return 0.0;
        }
        double logDice = Math.log(numerator / denominator) / Math.log(2) + 14;
        return Math.max(0, Math.min(14, logDice)); // Clamp to [0, 14]
    }

    /**
     * Execute a custom CQL query and return matching sentences.
     */
    public List<ConcordanceResult> executeQuery(String cqlPattern, int maxResults)
            throws IOException {

        CQLPattern pattern = new CQLParser().parse(cqlPattern);
        SpanQuery query = compiler.compile(pattern);

        TopDocs topDocs = searcher.search(query, maxResults);
        ScoreDoc[] hits = topDocs.scoreDocs;

        List<ConcordanceResult> results = new ArrayList<>();

        for (ScoreDoc hit : hits) {
            Document doc = searcher.storedFields().document(hit.doc);
            results.add(new ConcordanceResult(
                doc.get("sentence"),
                doc.get("lemma"),
                doc.get("tag"),
                doc.get("word"),
                Integer.parseInt(doc.get("start_offset")),
                Integer.parseInt(doc.get("end_offset"))
            ));
        }

        return results;
    }

    /**
     * Verify a CQL pattern against a token window with support for labeled positions.
     * This method uses the CQLVerifier to check exact pattern matching.
     */
    public boolean verifyPattern(CQLPattern pattern, TokenWindow window, int headwordPosition) {
        CQLVerifier verifier = new CQLVerifier();
        CQLVerifier.VerificationResult result = verifier.verifyForCollocate(pattern, window, headwordPosition);
        return result.isMatched();
    }

    /**
     * Load tokens for a sentence window around the given headword position.
     */
    public TokenWindow loadTokenWindow(int headwordDocId, int headwordPosition, String sentenceId, int windowSize)
            throws IOException {
        List<Token> tokens = new ArrayList<>();
        int startDocId = Math.max(0, headwordDocId - windowSize);
        int endDocId = Math.min(reader.maxDoc() - 1, headwordDocId + windowSize);

        // Collect documents for the window
        List<Document> docs = new ArrayList<>();
        for (int docId = startDocId; docId <= endDocId; docId++) {
            try {
                Document doc = searcher.storedFields().document(docId);
                String docSentence = doc.get("sentence");

                // Only include documents from the same sentence
                if (sentenceId != null && docSentence != null && docSentence.equals(doc.get("sentence"))) {
                    docs.add(doc);
                }
            } catch (Exception e) {
                // Skip invalid documents
            }
        }

        if (docs.isEmpty()) {
            return new TokenWindow(tokens, startDocId, endDocId, 0);
        }

        // Build tokens from documents
        for (Document doc : docs) {
            String lemma = doc.get("lemma");
            String word = doc.get("word");
            String tag = doc.get("tag");
            String posGroup = doc.get("pos_group");
            int position = Integer.parseInt(doc.get("position"));
            String sentence = doc.get("sentence");

            int sid = 0;
            try {
                sid = Integer.parseInt(doc.get("doc_id"));
            } catch (NumberFormatException e) {
                // Use 0 as fallback
            }

            tokens.add(new Token(lemma, word, tag, posGroup, position, sid, sentence));
        }

        return new TokenWindow(tokens, startDocId, endDocId,
            tokens.isEmpty() ? 0 : tokens.get(0).getSentenceId());
    }

    /**
     * Check if a pattern has labeled positions (requires verifier).
     */
    public boolean hasLabeledPositions(CQLPattern pattern) {
        for (CQLPattern.PatternElement element : pattern.getElements()) {
            if (element.getPosition() > 0) {
                return true;
            }
        }
        return false;
    }

    public static class WordSketchResult {
        private final String lemma;
        private final String pos;
        private final long frequency;
        private final double logDice;
        private final double relativeFrequency;
        private final List<String> examples;

        public WordSketchResult(String lemma, String pos, long frequency,
                               double logDice, double relativeFrequency,
                               List<String> examples) {
            this.lemma = lemma;
            this.pos = pos;
            this.frequency = frequency;
            this.logDice = logDice;
            this.relativeFrequency = relativeFrequency;
            this.examples = examples;
        }

        public String getLemma() { return lemma; }
        public String getPos() { return pos; }
        public long getFrequency() { return frequency; }
        public double getLogDice() { return logDice; }
        public double getRelativeFrequency() { return relativeFrequency; }
        public List<String> getExamples() { return examples; }
    }

    public static class ConcordanceResult {
        private final String sentence;
        private final String lemma;
        private final String tag;
        private final String word;
        private final int startOffset;
        private final int endOffset;

        public ConcordanceResult(String sentence, String lemma, String tag,
                                String word, int startOffset, int endOffset) {
            this.sentence = sentence;
            this.lemma = lemma;
            this.tag = tag;
            this.word = word;
            this.startOffset = startOffset;
            this.endOffset = endOffset;
        }

        public String getSentence() { return sentence; }
        public String getLemma() { return lemma; }
        public String getTag() { return tag; }
        public String getWord() { return word; }
        public int getStartOffset() { return startOffset; }
        public int getEndOffset() { return endOffset; }
    }

    public void close() throws IOException {
        reader.close();
    }

    /**
     * Get frequency of a specific lemma in the index.
     */
    public long getLemmaFrequency(String lemma) throws IOException {
        return reader.docFreq(new Term("lemma", lemma));
    }

    /**
     * Find words by POS tag pattern (e.g., "JJ*" for adjectives, "NN*" for nouns).
     */
    public List<WordSketchResult> findByTagPattern(String tagPattern, int maxResults) throws IOException {
        org.apache.lucene.index.Term term = new org.apache.lucene.index.Term("tag", tagPattern.replace("*", ".*"));
        org.apache.lucene.search.WildcardQuery query = new org.apache.lucene.search.WildcardQuery(term);
        org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper<?> spanQuery =
            new org.apache.lucene.queries.spans.SpanMultiTermQueryWrapper<>(query);

        TopDocs topDocs = searcher.search(spanQuery, maxResults * 10);
        ScoreDoc[] hits = topDocs.scoreDocs;

        Map<String, Long> lemmaFreqs = new HashMap<>();
        Map<String, String> examples = new HashMap<>();

        for (ScoreDoc hit : hits) {
            Document doc = searcher.storedFields().document(hit.doc);
            String lemma = doc.get("lemma");
            String sentence = doc.get("sentence");

            if (lemma != null) {
                lemmaFreqs.merge(lemma, 1L, Long::sum);
                if (!examples.containsKey(lemma)) {
                    examples.put(lemma, sentence);
                }
            }
        }

        List<WordSketchResult> results = new ArrayList<>();
        for (Map.Entry<String, Long> entry : lemmaFreqs.entrySet()) {
            results.add(new WordSketchResult(
                entry.getKey(), "", entry.getValue(),
                Math.log10(entry.getValue() + 1) * 2,
                (double) entry.getValue() / hits.length,
                Collections.singletonList(examples.get(entry.getKey()))
            ));
        }

        results.sort((a, b) -> Long.compare(b.getFrequency(), a.getFrequency()));
        return results.subList(0, Math.min(maxResults, results.size()));
    }

    public static void main(String[] args) throws IOException {
        String indexPath = args.length > 0 ? args[0] : "target/corpus-1m";

        System.out.println("Word Sketch Query Executor - 1M Token Corpus");
        System.out.println("==============================================");
        System.out.println(String.format("Index: %s", indexPath));

        try (WordSketchExecutor executor = new WordSketchExecutor(indexPath)) {
            // Debug: Check what tags exist in the index
            System.out.println("Checking index structure...");
            System.out.println("Sample lemma frequencies:");
            String[] testLemmas = {"time", "problem", "good", "people", "new"};
            for (String lemma : testLemmas) {
                long freq = executor.executor.getLemmaFrequency(lemma);
                System.out.println("  " + lemma + ": " + freq);
            }

            // Debug: Check what the CQL pattern parses to
            String testPattern = "[tag=\"JJ.*\"]";
            System.out.println("\nTesting CQL pattern: " + testPattern);
            try {
                var parsed = new CQLParser().parse(testPattern);
                System.out.println("Parsed elements: " + parsed.getElements().size());
                for (var elem : parsed.getElements()) {
                    System.out.println("  target='" + elem.getTarget() + "', position=" + elem.getPosition() +
                        ", hasConstraint=" + (elem.getConstraint() != null));
                    if (elem.getConstraint() != null) {
                        System.out.println("    constraint: field=" + elem.getConstraint().getField() +
                            ", pattern=" + elem.getConstraint().getPattern());
                    }
                }

                // Compile to see what query is produced
                var compiler = new CQLToLuceneCompiler();
                var query = compiler.compile(parsed);
                System.out.println("Query type: " + query.getClass().getSimpleName());
            } catch (Exception e) {
                System.out.println("Parse error: " + e.getMessage());
            }

            // Test a direct query
            System.out.println("\nTesting direct tag query [tag=\"JJ\"]...");
            try {
                var directResults = executor.executor.executeQuery("[tag=\"JJ\"]", 10);
                System.out.println("Direct query found " + directResults.size() + " results");
                for (var r : directResults) {
                    System.out.println("  " + r.getWord() + "/" + r.getTag() + ": " +
                        (r.getSentence() != null ? r.getSentence().substring(0, Math.min(80, r.getSentence().length())) : "null"));
                }
            } catch (Exception e) {
                System.out.println("Direct query error: " + e.getMessage());
            }

            // Debug: Check the actual Lucene query being built
            System.out.println("\nDebug: Testing wildcard query directly...");
            try {
                var pattern = new CQLParser().parse("[tag=\"JJ*\"]");
                System.out.println("Pattern elements: " + pattern.getElements().size());
                var compiler = new CQLToLuceneCompiler();
                var query = compiler.compile(pattern);
                System.out.println("Query: " + query);

                // Test search
                var searcher = new IndexSearcher(executor.executor.reader);
                var topDocs = searcher.search(query, 100);
                System.out.println("Search found " + topDocs.totalHits + " hits");
            } catch (Exception e) {
                System.out.println("Debug error: " + e.getMessage());
                e.printStackTrace();
            }

            System.out.println("\n=== Word Sketch: problem (adjectives) ===");
            System.out.println("Pattern: [tag=\"jj.*\"] ~ {0,3}");
            System.out.println();

            List<WordSketchResult> results = executor.findCollocations(
                "problem", "[tag=\"jj.*\"] ~ {0,3}", 0, 20);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }
            System.out.println();

            // Test adjective collocates of "time"
            System.out.println("=== Word Sketch: time (adjectives) ===");
            System.out.println("Pattern: [tag=\"jj.*\"] ~ {0,3}");
            System.out.println();

            results = executor.findCollocations("time", "[tag=\"jj.*\"] ~ {0,3}", 0, 20);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }
            System.out.println();

            // Test verbs with "people"
            System.out.println("=== Word Sketch: people (verbs) ===");
            System.out.println("Pattern: [tag=\"vb.*\"] ~ {0,3}");
            System.out.println();

            results = executor.findCollocations("people", "[tag=\"vb.*\"] ~ {0,3}", 0, 15);

            for (int i = 0; i < Math.min(10, results.size()); i++) {
                WordSketchResult r = results.get(i);
                System.out.println(String.format("  %-15s %,5d  logDice: %.2f  %s",
                    r.getLemma(), r.getFrequency(), r.getLogDice(),
                    r.getExamples().isEmpty() ? "" : r.getExamples().get(0).replace("\n", " ")));
            }

        } catch (Exception e) {
            System.err.println("Error: " + e.getMessage());
            e.printStackTrace();
        }
    }

    /**
     * Simple wrapper for testing - uses WordSketchQueryExecutor internally.
     */
    public static class WordSketchExecutor implements AutoCloseable {
        private final WordSketchQueryExecutor executor;

        public WordSketchExecutor(String indexPath) throws IOException {
            this.executor = new WordSketchQueryExecutor(indexPath);
        }

        public List<WordSketchResult> findCollocations(String headword, String pattern,
                                                        double minLogDice, int maxResults) throws IOException {
            return executor.findCollocations(headword, pattern, minLogDice, maxResults);
        }

        @Override
        public void close() throws IOException {
            executor.close();
        }
    }
}
